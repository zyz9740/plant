{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    " \n",
    "#训练集，将相对目录./data下的cifar-10-batches-py文件夹中的全部数据（50000张图片作为训练数据）加载到内存中，若download为True时，会自动从网上下载数据并解压\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    " \n",
    "#将训练集的50000张图片划分成12500份，每份4张图，用于mini-batch输入。shffule=True在表示不同批次的数据遍历时，打乱顺序。num_workers=2表示使用两个子进程来加载数据\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    " \n",
    "#测试集，将相对目录./data下的cifar-10-batches-py文件夹中的全部数据（10000张图片作为测试数据）加载到内存中，若download为True时，会自动从网上下载数据并解压\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    " \n",
    "#将测试集的10000张图片划分成2500份，每份4张图，用于mini-batch输入。\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # 定义conv1函数的是图像卷积函数：输入为图像（3个频道，即彩色图）,输出为6张特征图, 卷积核为5x5正方形\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    " \n",
    "criterion = nn.CrossEntropyLoss() #叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  #使用SGD（随机梯度下降）优化，学习率为0.001，动量为0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.212\n",
      "[1,  4000] loss: 1.192\n",
      "[1,  6000] loss: 1.184\n",
      "[1,  8000] loss: 1.182\n",
      "[1, 10000] loss: 1.182\n",
      "[1, 12000] loss: 1.163\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1): # 遍历数据集两次\n",
    "     \n",
    "    running_loss = 0.0\n",
    "    #enumerate(sequence, [start=0])，i序号，data是数据\n",
    "    for i, data in enumerate(trainloader, 0): \n",
    "        # get the inputs\n",
    "        inputs, labels = data   #data的结构是：[4x3x32x32的张量,长度4的张量]\n",
    "         \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)  #把input数据从tensor转为variable\n",
    "         \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() #将参数的grad值初始化为0\n",
    "         \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels) #将output和labels使用叉熵计算损失\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #用SGD更新参数\n",
    "         \n",
    "        # 每2000批数据打印一次平均loss值\n",
    "        running_loss += loss.item()  #loss本身为Variable类型，所以要使用data获取其Tensor，因为其为标量，所以取0\n",
    "        if i % 2000 == 1999: # 每2000批打印一次\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    " \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    #print outputs.data\n",
    "    _, predicted = torch.max(outputs.data, 1)  #outputs.data是一个4x10张量，将每一行的最大的那一列的值和序号各自组成一个一维张量返回，第一个是值的张量，第二个是序号的张量。\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()   #两个一维张量逐行对比，相同的行记为1，不同的行记为0，再利用sum(),求总和，得到相同的个数。\n",
    " \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "das += 1\n",
    "print(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'net':net.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state,'haha.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
